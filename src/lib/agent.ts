import { streamText, generateText, tool, stepCountIs } from 'ai';
import { createAmazonBedrock } from '@ai-sdk/amazon-bedrock';
import { z } from 'zod';
import { generatePreviewImage, generateImageWithReferences } from './gemini';
import agentPrompt from './prompts/agent.md';
import enhancePrompt from './prompts/enhance.md';
import creativePrompt from './prompts/creative.md';
import wildPrompt from './prompts/wild.md';
import captionsPrompt from './prompts/captions.md';
import generateImageToolPrompt from './prompts/generate_image_tool.md';
import type { Tip } from '@/types';

// ---------------------------------------------------------------------------
// Model
// ---------------------------------------------------------------------------

const bedrock = createAmazonBedrock({
  region: process.env.AWS_REGION?.trim(),
  accessKeyId: process.env.AWS_ACCESS_KEY_ID?.trim(),
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY?.trim(),
});
const MODEL = bedrock('us.anthropic.claude-sonnet-4-5-20250929-v1:0');

// ---------------------------------------------------------------------------
// Types
// ---------------------------------------------------------------------------

interface AgentContext {
  currentImage: string;    // base64 data URL â€“ updated after each generation
  originalImage?: string;  // base64 data URL â€“ the very first image, never changes
  projectId: string;
  /** Images generated during this run (base64). Streamed to frontend out-of-band. */
  generatedImages: string[];
}

export type AgentStreamEvent =
  | { type: 'status'; text: string }
  | { type: 'content'; text: string }
  | { type: 'new_turn' }  // signals start of a new assistant response (after tool result)
  | { type: 'image'; image: string }
  | { type: 'tool_call'; tool: string; input: Record<string, unknown>; images?: string[] }
  | { type: 'done' }
  | { type: 'error'; message: string };

// ---------------------------------------------------------------------------
// Skill template map â€” reuses already-imported .md files
// ---------------------------------------------------------------------------

const SKILL_PROMPTS: Record<string, string> = {
  enhance: enhancePrompt,
  creative: creativePrompt,
  wild: wildPrompt,
  captions: captionsPrompt,
};

// ---------------------------------------------------------------------------
// System prompt (bundled via webpack asset/source)
// ---------------------------------------------------------------------------

function getAgentSystemPrompt(): string {
  return agentPrompt;
}

// ---------------------------------------------------------------------------
// Tools (Vercel AI SDK style, closure over AgentContext)
// ---------------------------------------------------------------------------

function createTools(ctx: AgentContext) {
  return {
    generate_image: tool({
      description: generateImageToolPrompt,
      inputSchema: z.object({
        editPrompt: z.string().describe('The specific creative direction for this edit (English). When skill is set, write only the direction â€” template rules are auto-injected.'),
        skill: z.enum(['enhance', 'creative', 'wild', 'captions']).optional().describe('Activate a skill template. See tool description for routing rules.'),
        useOriginalAsReference: z.boolean().optional().describe('Set true when you judge that the original photo would help as a reference â€” e.g. face has drifted, colors changed, user wants to restore something, or after many edits. Default false = single image edit.'),
        aspectRatio: z.string().optional().describe('Target aspect ratio e.g. "4:5", "1:1", "16:9"'),
      }),
      execute: async ({ editPrompt, skill, useOriginalAsReference, aspectRatio }) => {
        const hasOriginal = ctx.originalImage && ctx.originalImage !== ctx.currentImage;

        // Inject skill template if provided
        const skillTemplate = skill ? SKILL_PROMPTS[skill] : null;
        const finalPrompt = skillTemplate
          ? `${skillTemplate}\n\n---\n\nAPPLY THE ABOVE SKILL TO THIS SPECIFIC REQUEST:\n${editPrompt}`
          : editPrompt;

        console.log(`\nğŸ¨ [generate_image] skill=${skill ?? 'none'} useOriginalAsReference=${!!useOriginalAsReference} hasOriginal=${!!hasOriginal}\neditPrompt:\n${editPrompt}\n`);

        let result: string | null;
        if (useOriginalAsReference && hasOriginal) {
          // Two-image mode: current as edit base, original as reference
          console.log('ğŸ“¸ Two-image mode (original as reference)');
          result = await generateImageWithReferences(
            [
              { url: ctx.currentImage,   role: 'Image 1 = å½“å‰ç¼–è¾‘ç‰ˆæœ¬ã€ç¼–è¾‘åŸºç¡€ï¼Œä¿æŒæ­¤å›¾çš„æ„å›¾/åœºæ™¯/äººç‰©ä½ç½®ã€‘' },
              { url: ctx.originalImage!, role: 'Image 2 = åŸå›¾ã€å‚è€ƒåŸºå‡†ï¼šç”¨äºè¿˜åŸä»»ä½•å·²åç¦»çš„å…ƒç´ ï¼ˆäººè„¸/é¢œè‰²/èƒŒæ™¯ç­‰ï¼‰ï¼Œæ„å›¾åŸºç¡€ä»ä»¥ Image 1 ä¸ºå‡†ã€‘' },
            ],
            finalPrompt,
            aspectRatio,
          );
        } else {
          // Single-image mode (default): keeps Gemini in edit-in-place mode
          console.log('ğŸ“¸ Single-image mode');
          result = await generatePreviewImage(ctx.currentImage, finalPrompt, aspectRatio);
        }

        if (!result) {
          return { success: false as const, message: 'Image generation failed. Try a different prompt.' };
        }
        ctx.currentImage = result;
        ctx.generatedImages.push(result);
        return { success: true as const, message: 'Image generated successfully and shown to the user.' };
      },
    }),

    analyze_image: tool({
      description: 'See and analyze the current photo. Returns the image so you can view it directly with your vision capabilities.',
      inputSchema: z.object({
        question: z.string().optional().describe('Optional focus area for the analysis'),
      }),
      execute: async ({ question }) => {
        const base64Data = ctx.currentImage.replace(/^data:image\/\w+;base64,/, '');
        const mimeType = ctx.currentImage.startsWith('data:image/png') ? 'image/png' : 'image/jpeg';
        return { base64Data, mimeType, question };
      },
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      toModelOutput({ output }: { output: any }) {
        return {
          type: 'content' as const,
          value: [
            { type: 'media' as const, data: output.base64Data, mediaType: output.mimeType },
            {
              type: 'text' as const,
              text: output.question
                ? `Analyze the image above, focusing on: ${output.question}`
                : 'Analyze this image in detail for photo editing purposes.',
            },
          ],
        };
      },
    }),

  };
}

// ---------------------------------------------------------------------------
// Agent runner â€“ async generator yielding SSE events
// ---------------------------------------------------------------------------

// Used for initial upload analysis
const ANALYSIS_PROMPT_INITIAL = `æè¿°è¿™å¼ ç…§ç‰‡é‡Œçš„å†…å®¹ï¼Œ1-2å¥ï¼Œè¯­æ°”åƒæœ‹å‹åˆ†äº«ã€‚ç›´æ¥ä»ä¸»ä½“å¼€å§‹è¯´ï¼ˆ"ä¸€ä¸ª..."/"ç”»é¢é‡Œ..."ï¼‰ã€‚ç¦æ­¢ç”¨"æˆ‘æ¥çœ‹çœ‹"/"è®©æˆ‘çœ‹ä¸€ä¸‹"ç­‰ä»»ä½•é“ºå«è¯­ã€‚`;

// Used for post-edit analysis â€” acknowledges the edit context
const ANALYSIS_PROMPT_POSTEDIT = `På®Œå›¾äº†ï¼Œçœ‹çœ‹æ•ˆæœã€‚ä»¥"På®Œä¹‹åï¼Œ"å¼€å¤´ï¼Œç”¨1å¥è¯æè¿°ä¸€ä¸‹ç°åœ¨è¿™å¼ å›¾çš„æ•´ä½“æ•ˆæœå’Œæ°›å›´ã€‚ç¦æ­¢ç”¨"æˆ‘æ¥çœ‹çœ‹"ç­‰é“ºå«è¯­ï¼Œç›´æ¥è¯´ç»“æœã€‚`;

export async function* runMakaronAgent(
  prompt: string,
  currentImage: string,
  projectId: string,
  options?: { analysisOnly?: boolean; analysisContext?: 'initial' | 'post-edit'; tipReactionOnly?: boolean; originalImage?: string },
): AsyncGenerator<AgentStreamEvent> {
  const ctx: AgentContext = {
    currentImage,
    originalImage: options?.originalImage,
    projectId,
    generatedImages: [],
  };

  const allTools = createTools(ctx);
  let imagesSent = 0;
  let stepCount = 0;

  const analysisOnly = options?.analysisOnly ?? false;
  const tipReactionOnly = options?.tipReactionOnly ?? false;
  const maxSteps = analysisOnly ? 2 : tipReactionOnly ? 1 : 10;
  const analysisPrompt = options?.analysisContext === 'post-edit'
    ? ANALYSIS_PROMPT_POSTEDIT
    : ANALYSIS_PROMPT_INITIAL;

  // Determine which tools to expose
  // tipReactionOnly: no tools (text-only response)
  // analysisOnly: only analyze_image (agent uses tool to see the photo)
  // normal chat: all tools (generate_image + analyze_image)
  const tools = tipReactionOnly ? undefined : analysisOnly
    ? { analyze_image: allTools.analyze_image }
    : allTools;

  try {
    const result = streamText({
      model: MODEL,
      system: getAgentSystemPrompt(),
      messages: [{ role: 'user', content: analysisOnly ? analysisPrompt : prompt }],
      ...(tools ? { tools } : {}),
      ...(analysisOnly && tools ? { activeTools: ['analyze_image' as const] } : {}),
      stopWhen: stepCountIs(maxSteps),
      onStepFinish: () => { stepCount++; },
    });

    for await (const event of result.fullStream) {
      // â”€â”€ Text delta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if (event.type === 'text-delta') {
        yield { type: 'content', text: event.text };
        continue;
      }

      // â”€â”€ Tool call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if (event.type === 'tool-call') {
        if (event.toolName === 'analyze_image') {
          const q = (event.input as { question?: string }).question;
          yield { type: 'status', text: q ? `åˆ†æå›¾ç‰‡ï¼š${q.slice(0, 25)}` : 'åˆ†æå›¾ç‰‡' };
        } else if (event.toolName === 'generate_image') {
          yield { type: 'status', text: 'ç”Ÿæˆå›¾ç‰‡ä¸­...' };
        }
        let toolCallImages: string[] | undefined;
        if (event.toolName === 'generate_image') {
          const inp = event.input as { useOriginalAsReference?: boolean };
          const twoImageMode = inp.useOriginalAsReference && ctx.originalImage && ctx.originalImage !== ctx.currentImage;
          toolCallImages = twoImageMode
            ? [ctx.currentImage, ctx.originalImage!]
            : [ctx.currentImage];
        }
        yield {
          type: 'tool_call',
          tool: event.toolName,
          input: event.input as Record<string, unknown>,
          ...(toolCallImages ? { images: toolCallImages } : {}),
        };
        continue;
      }

      // â”€â”€ Tool result â€” flush generated images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if (event.type === 'tool-result') {
        while (imagesSent < ctx.generatedImages.length) {
          yield { type: 'image', image: ctx.generatedImages[imagesSent] };
          imagesSent++;
        }
        continue;
      }

      // â”€â”€ Error from stream â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if (event.type === 'error') {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const err = (event as any).error;
        const errMsg = err instanceof Error ? err.message : String(err);
        yield { type: 'error', message: errMsg };
        return;
      }

      // â”€â”€ New step start (after tool result, model begins next turn) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if (event.type === 'start-step' && stepCount > 0) {
        yield { type: 'new_turn' };
      }
    }

    // Flush remaining images
    while (imagesSent < ctx.generatedImages.length) {
      yield { type: 'image', image: ctx.generatedImages[imagesSent] };
      imagesSent++;
    }

    yield { type: 'done' };
  } catch (err) {
    yield { type: 'error', message: err instanceof Error ? err.message : String(err) };
  }
}

// ---------------------------------------------------------------------------
// Tips Skill: generate tips text using Claude (fast, ~2-3s vs Gemini ~15s)
// ---------------------------------------------------------------------------

const TIPS_JSON_FORMAT = `\n\nè¯·ä¸¥æ ¼ä»¥JSONæ•°ç»„æ ¼å¼å›å¤ï¼Œåªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š
[{"emoji":"1ä¸ªemoji","label":"ä¸­æ–‡3-6å­—åŠ¨è¯å¼€å¤´","desc":"ä¸­æ–‡10-25å­—çŸ­æè¿°","editPrompt":"Detailed English editing prompt","category":"enhance|creative|wild"}, ...]`;

const TIPS_PROMPTS: Record<'enhance' | 'creative' | 'wild' | 'captions', string> = {
  enhance: enhancePrompt,
  creative: creativePrompt,
  wild: wildPrompt,
  captions: captionsPrompt,
};

// Category-specific system prompts (restored from original gemini.ts structure)
const TIPS_CATEGORY_INFO: Record<'enhance' | 'creative' | 'wild' | 'captions', { cn: string; definition: string; selfCheck: string; rules: string }> = {
  enhance: {
    cn: 'enhanceï¼ˆä¸“ä¸šå¢å¼ºï¼‰',
    definition: 'enhance = è®©ç…§ç‰‡æ•´ä½“å˜å¥½çœ‹ï¼ˆå…‰å½±/è‰²å½©/é€šé€æ„Ÿï¼‰ï¼Œå˜åŒ–å¿…é¡»è‚‰çœ¼æ˜æ˜¾',
    selfCheck: `enhanceè‡ªæ£€ï¼š
- æ”¾åœ¨åŸå›¾æ—è¾¹ï¼Œä»»ä½•äººéƒ½èƒ½ä¸€çœ¼çœ‹å‡ºæå‡å—ï¼Ÿï¼ˆ"çœ‹ä¸å‡ºå˜åŒ–"=3åˆ†ï¼‰
- é£æ ¼ä¸ç…§ç‰‡æƒ…ç»ªåŒ¹é…å—ï¼Ÿï¼ˆæç¬‘ç…§ç‰‡é…é˜´æ²‰æš—è°ƒ=4åˆ†ï¼‰
- æœ‰é€šé€æ„Ÿ+æ™¯æ·±åˆ†ç¦»+è‰²è°ƒå±‚æ¬¡å—ï¼Ÿ
- enhanceå¯ä»¥è°ƒæ•´æ„å›¾ï¼Œä½†å¿…é¡»åŸºäºåŸå›¾â€”â€”ç¼–è¾‘åè¿˜èƒ½ä¸€çœ¼è®¤å‡ºæ˜¯åŒä¸€å¼ ç…§ç‰‡ï¼ˆ"ç”»é¢å˜åŒ–å¤ªå¤šäº†"=3åˆ†ï¼‰
- ç¼–è¾‘åçš„èƒŒæ™¯è¿˜æ˜¯åŸå›¾çš„èƒŒæ™¯å—ï¼Ÿenhanceæ˜¯æå‡åŸå›¾ä¸æ˜¯ç”Ÿæˆæ–°å›¾ï¼ˆ"èƒŒæ™¯è¢«æ¢æ‰äº†"=3åˆ†ï¼Œ"äººç‰©éƒ½å˜äº†"=1åˆ†ï¼‰`,
    rules: `âš ï¸ enhanceçš„editPromptå¿…é¡»åŒ…å«èƒŒæ™¯é”šå®šï¼š
"Keep the original background scene intact â€” enhance lighting and colors on the existing scene, do NOT replace or regenerate the background."`,
  },
  creative: {
    cn: 'creativeï¼ˆè¶£å‘³åˆ›æ„ï¼‰',
    definition: 'creative = å¾€ç”»é¢é‡ŒåŠ å…¥ä¸€ä¸ªä¸ç”»é¢å†…å®¹æœ‰å› æœå…³ç³»çš„æœ‰è¶£æ–°å…ƒç´ ',
    selfCheck: `creativeè‡ªæ£€ï¼ˆä¸‰é—®å…¨è¿‡æ‰è¾“å‡ºï¼‰ï¼š
- Q1 ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªå…ƒç´ ï¼Ÿèƒ½ä¸èƒ½ä¸€å¥è¯è¯´æ¸…"å› ä¸ºç”»é¢é‡Œæœ‰Xæ‰€ä»¥åŠ Y"ï¼Ÿè¯´ä¸æ¸…=æ¢ä¸€ä¸ª
- Q2 æƒ…ç»ªå¯¹å—ï¼Ÿè®©äººç¬‘/æƒŠå–œ=å¥½ï¼Œè®©äººå®³æ€•/å›°æƒ‘=æ¢
- Q3 è¿™ä¸ªåˆ›æ„èƒ½ç”¨åœ¨å…¶ä»–ç…§ç‰‡ä¸Šå—ï¼Ÿèƒ½=å¤ªé€šç”¨=æ¢ä¸€ä¸ª`,
    rules: `creativeå“è´¨æ ‡å‡†ï¼š
- åŠ å…¥çš„åŠ¨ç‰©/è§’è‰²å¿…é¡»æ˜¯photorealisticå†™å®é£ï¼ˆcartoon/å¡é€š=è´´çº¸æ„Ÿï¼‰
- è¶³å¤Ÿå¤§ä¸”æ˜¾çœ¼ï¼Œè‡³å°‘å ç”»é¢5-10%é¢ç§¯
- å¿…é¡»ä¸äººç‰©æœ‰äº’åŠ¨/çœ¼ç¥äº¤æµï¼Œä¸èƒ½åƒè´´çº¸`,
  },
  wild: {
    cn: 'wildï¼ˆç–¯ç‹‚è„‘æ´ï¼‰',
    definition: 'wild = è®©ç”»é¢ä¸­å·²æœ‰çš„ç‰©å“å‘ç”Ÿç–¯ç‹‚å˜åŒ–ï¼ˆä¸æ˜¯åŠ æ–°ä¸œè¥¿ï¼ï¼‰',
    selfCheck: `wildè‡ªæ£€ï¼ˆå››é—®å…¨è¿‡æ‰è¾“å‡ºï¼‰ï¼š
- Q1 å˜åŒ–çš„ä¸»è§’æ˜¯ç”»é¢ä¸­å·²æœ‰çš„ä»€ä¹ˆä¸œè¥¿ï¼ŸæŒ‡ä¸å‡ºæ¥=ä¸æ˜¯wild
- Q2 å˜åŒ–å¤Ÿå¤§å—ï¼Ÿä¸€çœ¼å°±èƒ½çœ‹åˆ°å˜åŒ–=å¥½ã€‚æ”¹é•œç‰‡/çœ¼é•œåå°„å†…å®¹=å¤ªå°ä¸å¤Ÿå¤§(3åˆ†"çœ¼é•œideaå‚»")
- Q3 å˜åŒ–æ˜¯åŸºäºç‰©å“æœ¬èº«ç‰¹ç‚¹è¿˜æ˜¯éšä¾¿å¥—çš„ï¼Ÿè¡¨é¢è§†è§‰ç±»æ¯”ï¼ˆå±‚çŠ¶=è›‹ç³•/æŠ¹èŒ¶ã€åœ†å½¢=çƒï¼‰=æ¢ä¸€ä¸ªã€‚"å˜æˆé£Ÿç‰©/é¥®å“"é™¤éå¨æˆ¿åœºæ™¯å¦åˆ™=ä¸‡é‡‘æ²¹å¥—è·¯
- Q4 è¿™ä¸ªå˜åŒ–ä¼šä¸ä¼šè®©äººä¸é€‚/ææ€–ï¼Ÿâ†’ æ¢ä¸€ä¸ªæœ‰è¶£çš„æ–¹å‘`,
    rules: `wildé¢å¤–è§„åˆ™ï¼šåªé€‰ç”»é¢ä¸­é‡è¦/æ˜¾çœ¼çš„å…ƒç´ åšå˜åŒ–ï¼Œä¸è¦é€‰è¾¹ç¼˜æ¨¡ç³Šçš„å°ç‰©ä»¶`,
  },
  captions: {
    cn: 'captionsï¼ˆåˆ›æ„æ–‡æ¡ˆï¼‰',
    definition: 'captions = ä¸ºç…§ç‰‡æ·»åŠ ä¸å†…å®¹é«˜åº¦ç›¸å…³çš„åˆ›æ„æ–‡å­—å åŠ ï¼Œå­—ä½“é£æ ¼å¿…é¡»ä¸ç…§ç‰‡æƒ…ç»ªä¸€è‡´',
    selfCheck: `captionsè‡ªæ£€ï¼ˆä¸‰é—®å…¨è¿‡æ‰è¾“å‡ºï¼‰ï¼š
- Q1 è¿™æ®µæ–‡å­—åªé€‚åˆè¿™å¼ ç…§ç‰‡å—ï¼Ÿæ¢åˆ°å…¶ä»–ç…§ç‰‡ä¸Šè¿˜åˆé€‚=å¤ªé€šç”¨=é‡å†™
- Q2 å­—ä½“é£æ ¼ä¸ç”»é¢æƒ…ç»ªåŒ¹é…å—ï¼Ÿï¼ˆç«¥è¶£ç…§é…ä¸¥è‚ƒå­—ä½“=4åˆ†ï¼Œæç¬‘é…ä¼˜é›…èŠ±ä½“=3åˆ†ï¼‰
- Q3 æœ‰metadataæ—¶è‡ªç„¶èå…¥äº†å—ï¼Ÿæœ‰åœ°ç‚¹/æ—¶é—´å¿…é¡»ç»“åˆè¿›æ–‡æ¡ˆ`,
    rules: `captionså“è´¨æ ‡å‡†ï¼š
- æ–‡å­—å¿…é¡»æ˜¯photorealisticæ¸²æŸ“ï¼Œä¸æ˜¯å¡é€šè´´çº¸
- æ˜ç¡®å†™å‡ºè¦å åŠ çš„æ–‡å­—å†…å®¹ï¼ˆä¸èƒ½è®©Geminiè‡ªå·±ç¼–ï¼‰
- ä¸€ä¸ªtipåªåŠ ä¸€å¥/ä¸€è¡Œæ–‡å­—ï¼Œç®€æ´æœ‰åŠ›
- ä¸¤ä¸ªtipé£æ ¼å¿…é¡»ä¸åŒï¼ˆå¦‚ä¸€ä¸­ä¸€è‹±ï¼Œæˆ–ä¸€ç«¥è¶£ä¸€ç®€æ´ï¼‰`,
  },
};

function buildTipsSystemPrompt(category: 'enhance' | 'creative' | 'wild' | 'captions'): string {
  const info = TIPS_CATEGORY_INFO[category];
  const labelNote = category === 'captions'
    ? 'labelå¿…é¡»ç”¨ä¸­æ–‡3-6å­—ï¼ŒåŠ¨è¯å¼€å¤´ï¼Œå¹¶å°½é‡åŒ…å«åœ°ç‚¹/åœºæ™¯ç­‰å…·ä½“ä¿¡æ¯ï¼ˆå¦‚"è¿ªå£«å°¼æµ·æŠ¥"ã€"æ¢¯ç”°æ—ç™½"ã€"çº½çº¦èƒ¶ç‰‡"ï¼‰ã€‚'
    : 'labelå¿…é¡»ç”¨ä¸­æ–‡3-6å­—ï¼ŒåŠ¨è¯å¼€å¤´ã€‚';
  return `ä½ æ˜¯å›¾ç‰‡ç¼–è¾‘å»ºè®®ä¸“å®¶ã€‚åˆ†æå›¾ç‰‡åç”Ÿæˆ2æ¡${info.cn}ç¼–è¾‘å»ºè®®ã€‚${labelNote}editPromptç”¨è‹±æ–‡ï¼Œæå…¶å…·ä½“ã€‚

${info.definition}

âš ï¸ ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­äººè„¸å¤§å°ï¼
åˆ†æå›¾ç‰‡æ—¶é¦–å…ˆåˆ¤æ–­äººè„¸åœ¨ç”»é¢ä¸­çš„å æ¯”ï¼š
- å¤§è„¸ï¼ˆç‰¹å†™/åŠèº«ç…§ï¼Œè„¸éƒ¨å ç”»é¢>10%ï¼‰â†’ æ­£å¸¸å¤„ç†
- å°è„¸ï¼ˆå…¨èº«ç…§/åˆç…§/è¿œæ™¯/å¹¿è§’ï¼Œè„¸éƒ¨å ç”»é¢<10%ï¼‰â†’ è§¦å‘å°è„¸ä¿æŠ¤æ¨¡å¼
å°è„¸ä¿æŠ¤æ¨¡å¼ä¸‹æ‰€æœ‰editPromptå¿…é¡»åŒ…å«ï¼š
"CRITICAL: Faces in this photo are small. Leave ALL face areas completely untouched â€” do NOT sharpen, enhance, retouch, relight, resize, or process any face region in any way. Treat face areas as if they are masked off and invisible to you."
å°è„¸æ—¶äººç‰©ååº”åªèƒ½ç”¨èº«ä½“è¯­è¨€ï¼ˆèº«ä½“åä»°/è½¬å¤´/æ‰‹æŒ‡å‘å˜åŒ–ï¼‰ï¼Œç»ä¸èƒ½è¦æ±‚é¢éƒ¨è¡¨æƒ…å˜åŒ–ã€‚

è‡ªæ£€æ¡†æ¶ï¼ˆè¾“å‡ºæ¯ä¸ªtipå‰å…ˆè¿‡ä¸€éï¼‰ï¼š

${info.selfCheck}

${info.rules}

âš ï¸ äººè„¸ä¿çœŸæ˜¯æœ€å¤§æ‰£åˆ†é¡¹ï¼æ¶‰åŠäººç‰©çš„editPromptå¿…é¡»åŒ…å«ï¼š
"Preserve each person's identity, bone structure, face shape exactly. Do not make faces wider or rounder."

âš ï¸ æ‰€æœ‰editPromptéƒ½å¿…é¡»åŒ…å«èƒŒæ™¯å‡€åŒ–ï¼š
"Clean up the scene like a professional photographer would before shooting: remove any object that draws attention away from the main subject but adds no compositional value. Replace cleaned areas with natural-looking continuation of the scene."

2ä¸ªtipå¿…é¡»é€‰ä¸åŒæ–¹å‘ã€‚ç»“å°¾åŠ "Do NOT add any text, watermarks, or borders."`;
}

export async function* streamTipsWithClaude(
  imageBase64: string,
  category: 'enhance' | 'creative' | 'wild' | 'captions',
  metadata?: { takenAt?: string; location?: string },
): AsyncGenerator<Tip> {
  const dataUrl = imageBase64.startsWith('data:') ? imageBase64 : `data:image/jpeg;base64,${imageBase64}`;
  const template = TIPS_PROMPTS[category];
  const systemPrompt = buildTipsSystemPrompt(category);

  // Build metadata context string
  const metaLines: string[] = [];
  if (metadata?.takenAt) metaLines.push(`æ‹æ‘„æ—¶é—´ï¼š${metadata.takenAt}`);
  if (metadata?.location) metaLines.push(`æ‹æ‘„åœ°ç‚¹ï¼š${metadata.location}`);
  const metaContext = metaLines.length > 0
    ? `[ç…§ç‰‡å…ƒæ•°æ®]\n${metaLines.join('\n')}\nï¼ˆå¯ç”¨äºæ›´è´´åˆ‡çš„åˆ›æ„è”æƒ³ï¼Œä¾‹å¦‚åœ°ç‚¹ç‰¹è‰²å…ƒç´ ã€æ—¶é—´å¯¹åº”çš„å…‰çº¿æ°›å›´ç­‰ï¼‰\n\n`
    : '';

  const userPrompt = `${metaContext}åœ¨ç”Ÿæˆå»ºè®®ä¹‹å‰ï¼Œå…ˆåˆ†æè¿™å¼ å›¾ç‰‡ï¼šåˆ¤æ–­äººè„¸å¤§å°ï¼›è¯†åˆ«ç”»é¢ä¸­çš„å…·ä½“ç‰©å“/é£Ÿç‰©/é“å…·ï¼›åˆ¤æ–­ç…§ç‰‡æƒ…ç»ªåŸºè°ƒã€‚

åŸºäºåˆ†æï¼Œç»™å‡º2æ¡${category}ç¼–è¾‘å»ºè®®ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†è§„èŒƒï¼ˆå¿…é¡»éµå¾ªï¼‰ï¼š

${template}${TIPS_JSON_FORMAT}`;

  const { textStream } = streamText({
    model: MODEL,
    system: systemPrompt,
    messages: [
      {
        role: 'user',
        content: [
          { type: 'image', image: dataUrl },
          { type: 'text', text: userPrompt },
        ],
      },
    ],
  });

  // Collect full text then parse JSON
  let fullText = '';
  for await (const delta of textStream) {
    fullText += delta;
  }

  // Extract JSON array from response
  const jsonMatch = fullText.match(/\[[\s\S]*\]/);
  if (!jsonMatch) return;

  try {
    const tips = JSON.parse(jsonMatch[0]) as Tip[];
    for (const tip of tips) {
      if (tip.label && tip.editPrompt && tip.category) {
        yield tip;
      }
    }
  } catch { /* parse error, yield nothing */ }
}
