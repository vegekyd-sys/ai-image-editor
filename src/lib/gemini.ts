import { GoogleGenAI, Chat, Type } from '@google/genai';
import { Tip } from '@/types';
import enhancePrompt from './prompts/enhance.md';
import creativePrompt from './prompts/creative.md';
import wildPrompt from './prompts/wild.md';
import captionsPrompt from './prompts/captions.md';

// â”€â”€ Provider & Model Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Switch provider: 'google' = direct Google API, 'openrouter' = OpenRouter proxy
const PROVIDER = (process.env.AI_PROVIDER || 'google') as 'google' | 'openrouter';

// Image generation model
const MODEL = 'gemini-3-pro-image-preview';

const OPENROUTER_BASE = 'https://openrouter.ai/api/v1/chat/completions';
const OPENROUTER_MODEL = `google/${MODEL}`;

// Fast vision model for tips TEXT generation (much faster than image gen model)
const TIPS_MODEL = 'google/gemini-2.0-flash-001';

// â”€â”€ Google SDK singleton â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let _ai: GoogleGenAI | null = null;
function getAI() {
  if (!_ai) _ai = new GoogleGenAI({ apiKey: process.env.GOOGLE_API_KEY! });
  return _ai;
}

// â”€â”€ Shared Prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const SYSTEM_PROMPT = `ä½ æ˜¯ä¸–ç•Œä¸Šæœ€å¥½çš„ç…§ç‰‡ç¼–è¾‘AIã€‚ä½ èƒ½æ·±å…¥ç†è§£å›¾ç‰‡çš„æ¯ä¸ªç»†èŠ‚â€”â€”ä¸»ä½“ã€æƒ…ç»ªã€å…‰çº¿ã€æ„å›¾ã€ç¯å¢ƒã€è‰²å½©ã€çº¹ç†ã€ç‘•ç–µå’Œæ•…äº‹ã€‚

æ”¶åˆ°å›¾ç‰‡æ—¶ï¼Œç”¨ä¸­æ–‡ç®€çŸ­ç‚¹è¯„ï¼ˆ2-3å¥è¯ï¼Œå±•ç¤ºä½ çœŸçš„çœ‹æ‡‚äº†è¿™å¼ å›¾ï¼‰ã€‚

å½“ç”¨æˆ·è¦æ±‚ç¼–è¾‘å›¾ç‰‡æ—¶ï¼Œä½ ç›´æ¥ç”Ÿæˆç¼–è¾‘åçš„å›¾ç‰‡ã€‚ä¸è¦åªæ˜¯æè¿°è¦åšä»€ä¹ˆâ€”â€”ç›´æ¥ç”Ÿæˆå›¾ç‰‡ï¼ç”Ÿæˆå›¾ç‰‡åç”¨ä¸­æ–‡ç®€çŸ­æè¿°ä½ åšäº†ä»€ä¹ˆï¼ˆ1-2å¥è¯ï¼‰ã€‚

äººè„¸ä¿æŒè§„åˆ™ï¼š
- æ¯ä¸ªäººçš„èº«ä»½å¿…é¡»ä¿æŒï¼šç›¸åŒçš„è„¸å‹ã€çœ¼ç›ã€é¼»å­ã€å˜´å·´ã€é¢éƒ¨ç»“æ„
- çš®è‚¤å¯ä»¥ä¼˜åŒ–ï¼Œä½†éª¨éª¼ç»“æ„ä¸èƒ½å˜
- å‘å‹å‘è‰²ä¿æŒä¸å˜ï¼ˆé™¤éç¼–è¾‘è¦æ±‚æ”¹å˜ï¼‰
- è¡¨æƒ…å§¿åŠ¿ä¿æŒä¸å˜ï¼ˆé™¤éç¼–è¾‘è¦æ±‚æ”¹å˜ï¼‰

å°è„¸ä¿æŠ¤è§„åˆ™ï¼ˆå…¨èº«ç…§/åˆç…§/è¿œæ™¯/å¹¿è§’ç­‰äººè„¸å æ¯”å°çš„å›¾ç‰‡ï¼‰ï¼š
- å°è„¸å›¾ç‰‡ä¸­æ¯ä¸ªäººçš„é¢éƒ¨å¿…é¡»ä¸åŸå›¾å®Œå…¨ä¸€è‡´â€”â€”ä¸åšä»»ä½•é¢éƒ¨ä¿®æ”¹ã€è¡¥å…‰ã€ç¾é¢œ
- ç¼–è¾‘æ—¶å¦‚æœéœ€è¦äººç‰©æœ‰ååº”ï¼Œåªç”¨èº«ä½“è¯­è¨€ï¼ˆè½¬èº«ã€å€¾æ–œã€æ‰‹åŠ¿ï¼‰ï¼Œä¸æ”¹å˜é¢éƒ¨è¡¨æƒ…`;

// â”€â”€ Per-Category Tips Prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Tips are generated in 3 parallel calls (one per category) for faster loading.
// All rules live in the .md files â€” this is just role + format framing.

type TipCategory = 'enhance' | 'creative' | 'wild' | 'captions';

const CATEGORY_CN: Record<TipCategory, string> = {
  enhance: 'enhanceï¼ˆä¸“ä¸šå¢å¼ºï¼‰',
  creative: 'creativeï¼ˆè¶£å‘³åˆ›æ„ï¼‰',
  wild: 'wildï¼ˆç–¯ç‹‚è„‘æ´ï¼‰',
  captions: 'captionsï¼ˆåˆ›æ„æ–‡æ¡ˆï¼‰',
};

function buildCategorySystemPrompt(category: TipCategory): string {
  const labelNote = category === 'captions'
    ? 'labelå¿…é¡»ç”¨ä¸­æ–‡3-6å­—ï¼ŒåŠ¨è¯å¼€å¤´ï¼Œå¹¶å°½é‡åŒ…å«åœ°ç‚¹/åœºæ™¯ç­‰å…·ä½“ä¿¡æ¯ï¼ˆå¦‚"è¿ªå£«å°¼æµ·æŠ¥"ã€"æ¢¯ç”°æ—ç™½"ã€"çº½çº¦èƒ¶ç‰‡"ï¼‰ã€‚'
    : 'labelå¿…é¡»ç”¨ä¸­æ–‡3-6å­—ï¼ŒåŠ¨è¯å¼€å¤´ã€‚';
  return `ä½ æ˜¯å›¾ç‰‡ç¼–è¾‘å»ºè®®ä¸“å®¶ã€‚åˆ†æå›¾ç‰‡åç”Ÿæˆ2æ¡${CATEGORY_CN[category]}ç¼–è¾‘å»ºè®®ã€‚
${labelNote}editPromptç”¨è‹±æ–‡ï¼Œæå…¶å…·ä½“ã€‚`;
}

// Prompt templates bundled via webpack asset/source
const PROMPT_TEMPLATES: Record<TipCategory, string> = {
  enhance: enhancePrompt,
  creative: creativePrompt,
  wild: wildPrompt,
  captions: captionsPrompt,
};

function getPromptTemplate(category: TipCategory): string {
  return PROMPT_TEMPLATES[category];
}

// Google structured output schema (only used with Google provider + gemini-3)
const TIPS_SCHEMA = {
  type: Type.ARRAY,
  items: {
    type: Type.OBJECT,
    properties: {
      emoji: { type: Type.STRING, description: '1 emoji' },
      label: { type: Type.STRING, description: '3-6 Chinese chars, verb-first' },
      desc: { type: Type.STRING, description: '10-25 chars description' },
      editPrompt: { type: Type.STRING, description: 'Detailed English editing prompt' },
      category: { type: Type.STRING, enum: ['enhance', 'creative', 'wild', 'captions'] },
      aspectRatio: { type: Type.STRING, description: 'Only for recomposition tips', nullable: true },
    },
    required: ['emoji', 'label', 'desc', 'editPrompt', 'category'],
  },
};

const JSON_FORMAT_SUFFIX = `\n\nè¯·ä¸¥æ ¼ä»¥JSONæ•°ç»„æ ¼å¼å›å¤ï¼Œåªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚æ ¼å¼ï¼š
[{"emoji":"1ä¸ªemoji","label":"ä¸­æ–‡3-6å­—åŠ¨è¯å¼€å¤´","desc":"ä¸­æ–‡10-25å­—çŸ­æè¿°","editPrompt":"Detailed English editing prompt (MUST be in English)","category":"enhance|creative|wild|captions"}, ...]`;

// â”€â”€ OpenRouter Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function openrouterHeaders() {
  return {
    'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
    'Content-Type': 'application/json',
  };
}

function toOpenRouterImageContent(imageBase64: string, text: string) {
  // OpenRouter uses OpenAI vision format
  const dataUrl = imageBase64.startsWith('data:') ? imageBase64 : `data:image/jpeg;base64,${imageBase64}`;
  return [
    { type: 'image_url' as const, image_url: { url: dataUrl } },
    { type: 'text' as const, text },
  ];
}

// â”€â”€ Session Management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// Google sessions use SDK Chat objects; OpenRouter sessions use message arrays
type GoogleSession = { type: 'google'; chat: Chat; lastUsed: number };
type OpenRouterSession = {
  type: 'openrouter';
  messages: Array<{ role: string; content: string | Array<Record<string, unknown>> }>;
  lastUsed: number;
};
type Session = GoogleSession | OpenRouterSession;

const sessions = new Map<string, Session>();
const SESSION_TTL = 30 * 60 * 1000;

setInterval(() => {
  const now = Date.now();
  for (const [id, session] of sessions) {
    if (now - session.lastUsed > SESSION_TTL) {
      sessions.delete(id);
    }
  }
}, 5 * 60 * 1000);

function getOrCreateGoogleSession(projectId: string): Chat {
  const existing = sessions.get(projectId);
  if (existing && existing.type === 'google') {
    existing.lastUsed = Date.now();
    return existing.chat;
  }

  const chat = getAI().chats.create({
    model: MODEL,
    config: {
      systemInstruction: SYSTEM_PROMPT,
      responseModalities: ['TEXT'],
    },
  });

  sessions.set(projectId, { type: 'google', chat, lastUsed: Date.now() });
  return chat;
}

function getOrCreateOpenRouterSession(projectId: string): OpenRouterSession {
  const existing = sessions.get(projectId);
  if (existing && existing.type === 'openrouter') {
    existing.lastUsed = Date.now();
    return existing;
  }

  const session: OpenRouterSession = {
    type: 'openrouter',
    messages: [{ role: 'system', content: SYSTEM_PROMPT }],
    lastUsed: Date.now(),
  };
  sessions.set(projectId, session);
  return session;
}

export function resetSession(projectId: string): void {
  sessions.delete(projectId);
}

// â”€â”€ Streaming Chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export type ChatStreamEvent =
  | { type: 'content'; text: string }
  | { type: 'image'; image: string }
  | { type: 'done' };

export async function* chatStreamWithModel(
  projectId: string,
  message: string,
  imageBase64?: string,
  wantImage?: boolean,
  aspectRatio?: string,
): AsyncGenerator<ChatStreamEvent> {
  if (process.env.MOCK_AI === 'true') {
    const mockText = imageBase64
      ? 'è¿™æ˜¯ä¸€å¼ å¾ˆæ£’çš„ç…§ç‰‡ï¼æ„å›¾è‡ªç„¶ï¼Œè‰²å½©å’Œè°ã€‚æˆ‘ä¸ºä½ å‡†å¤‡äº†å‡ ç»„ç¼–è¾‘å»ºè®®ï¼Œå¯ä»¥ä»ä¸‹æ–¹å¡ç‰‡ä¸­é€‰æ‹©é¢„è§ˆæ•ˆæœã€‚'
      : 'å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å¤„ç†ã€‚';
    for (let i = 0; i < mockText.length; i += 3) {
      await new Promise(r => setTimeout(r, 30));
      yield { type: 'content', text: mockText.slice(i, i + 3) };
    }
    yield { type: 'done' };
    return;
  }

  if (PROVIDER === 'openrouter') {
    yield* chatStreamOpenRouter(projectId, message, imageBase64, wantImage, aspectRatio);
  } else {
    yield* chatStreamGoogle(projectId, message, imageBase64, wantImage, aspectRatio);
  }
}

// --- Google Provider ---
async function* chatStreamGoogle(
  projectId: string,
  message: string,
  imageBase64?: string,
  wantImage?: boolean,
  aspectRatio?: string,
): AsyncGenerator<ChatStreamEvent> {
  const chat = getOrCreateGoogleSession(projectId);

  const parts: Array<{ text?: string; inlineData?: { mimeType: string; data: string } }> = [];
  if (imageBase64) {
    const base64Data = imageBase64.replace(/^data:image\/\w+;base64,/, '');
    const mimeType = imageBase64.startsWith('data:image/png') ? 'image/png' : 'image/jpeg';
    parts.push({ inlineData: { mimeType, data: base64Data } });
  }
  parts.push({ text: message });

  const config: Record<string, unknown> = {};
  if (wantImage) {
    config.responseModalities = ['TEXT', 'IMAGE'];
    if (aspectRatio) {
      config.imageConfig = { aspectRatio };
    }
  } else {
    config.responseModalities = ['TEXT'];
  }

  const stream = await chat.sendMessageStream({ message: parts, config });

  for await (const chunk of stream) {
    const chunkParts = chunk.candidates?.[0]?.content?.parts;
    if (!chunkParts) continue;
    for (const part of chunkParts) {
      if (part.inlineData?.data) {
        const mime = part.inlineData.mimeType || 'image/png';
        yield { type: 'image', image: `data:${mime};base64,${part.inlineData.data}` };
      } else if (part.text) {
        yield { type: 'content', text: part.text };
      }
    }
  }
  yield { type: 'done' };
}

// --- OpenRouter Provider ---
async function* chatStreamOpenRouter(
  projectId: string,
  message: string,
  imageBase64?: string,
  wantImage?: boolean,
  aspectRatio?: string,
): AsyncGenerator<ChatStreamEvent> {
  const session = getOrCreateOpenRouterSession(projectId);

  // Build user message
  let userContent: string | Array<Record<string, unknown>>;
  if (imageBase64) {
    const dataUrl = imageBase64.startsWith('data:') ? imageBase64 : `data:image/jpeg;base64,${imageBase64}`;
    userContent = [
      { type: 'image_url', image_url: { url: dataUrl } },
      { type: 'text', text: message },
    ];
  } else {
    userContent = message;
  }
  session.messages.push({ role: 'user', content: userContent });

  const body: Record<string, unknown> = {
    model: OPENROUTER_MODEL,
    messages: session.messages,
    // Match Google API defaults for image editing fidelity
    temperature: 1.0,
    top_p: 0.95,
  };

  if (wantImage) {
    body.modalities = ['image', 'text'];
    body.temperature = 1.0;
    if (aspectRatio) {
      body.image_config = { aspect_ratio: aspectRatio };
    }
    // Image generation: non-streaming (images come in final response)
    body.stream = false;
  } else {
    // Text-only: use streaming
    body.stream = true;
  }

  const res = await fetch(OPENROUTER_BASE, {
    method: 'POST',
    headers: openrouterHeaders(),
    body: JSON.stringify(body),
  });

  if (!res.ok) {
    const errText = await res.text();
    throw new Error(`OpenRouter error ${res.status}: ${errText}`);
  }

  if (wantImage) {
    // Non-streaming: parse full JSON response
    const data = await res.json();
    const choice = data.choices?.[0]?.message;
    if (!choice) throw new Error('No response from OpenRouter');

    // Text content
    if (choice.content) {
      yield { type: 'content', text: choice.content };
    }

    // Images
    if (choice.images && Array.isArray(choice.images)) {
      for (const img of choice.images) {
        const url = img.image_url?.url || img.url;
        if (url) {
          yield { type: 'image', image: url };
        }
      }
    }

    // Save assistant message to history
    session.messages.push({ role: 'assistant', content: choice.content || '' });
  } else {
    // Streaming: parse SSE
    const reader = res.body!.getReader();
    const decoder = new TextDecoder();
    let buffer = '';
    let fullText = '';

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      buffer += decoder.decode(value, { stream: true });

      const lines = buffer.split('\n');
      buffer = lines.pop() || '';

      for (const line of lines) {
        if (!line.startsWith('data: ')) continue;
        const payload = line.slice(6).trim();
        if (payload === '[DONE]') break;
        try {
          const chunk = JSON.parse(payload);
          const delta = chunk.choices?.[0]?.delta;
          if (delta?.content) {
            fullText += delta.content;
            yield { type: 'content', text: delta.content };
          }
        } catch { /* skip malformed chunks */ }
      }
    }

    // Save assistant message to history
    session.messages.push({ role: 'assistant', content: fullText });
  }

  yield { type: 'done' };
}

// â”€â”€ Stateless Preview Image Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function generatePreviewImage(
  imageBase64: string,
  editPrompt: string,
  aspectRatio?: string,
): Promise<string | null> {
  // MOCK_AI only mocks tips/chat, not image generation
  if (PROVIDER === 'openrouter') {
    return generatePreviewImageOpenRouter(imageBase64, editPrompt, aspectRatio);
  } else {
    return generatePreviewImageGoogle(imageBase64, editPrompt, aspectRatio);
  }
}

async function generatePreviewImageGoogle(
  imageBase64: string,
  editPrompt: string,
  aspectRatio?: string,
): Promise<string | null> {
  const base64Data = imageBase64.replace(/^data:image\/\w+;base64,/, '');
  const mimeType = imageBase64.startsWith('data:image/png') ? 'image/png' : 'image/jpeg';

  const config: Record<string, unknown> = {
    responseModalities: ['IMAGE'],
  };
  if (aspectRatio) {
    config.imageConfig = { aspectRatio };
  }

  const result = await getAI().models.generateContent({
    model: MODEL,
    contents: [{
      role: 'user',
      parts: [
        { inlineData: { mimeType, data: base64Data } },
        { text: editPrompt },
      ],
    }],
    config,
  });

  const parts = result.candidates?.[0]?.content?.parts;
  if (!parts) return null;
  for (const part of parts) {
    if (part.inlineData?.data) {
      const mime = part.inlineData.mimeType || 'image/png';
      return `data:${mime};base64,${part.inlineData.data}`;
    }
  }
  return null;
}

async function generatePreviewImageOpenRouter(
  imageBase64: string,
  editPrompt: string,
  aspectRatio?: string,
): Promise<string | null> {
  const dataUrl = imageBase64.startsWith('data:')
    ? imageBase64
    : `data:image/jpeg;base64,${imageBase64}`;

  const body: Record<string, unknown> = {
    model: OPENROUTER_MODEL,
    stream: false,
    modalities: ['image', 'text'],
    temperature: 1.0,
    messages: [
      { role: 'system', content: SYSTEM_PROMPT },
      {
        role: 'user',
        content: [
          { type: 'image_url', image_url: { url: dataUrl } },
          { type: 'text', text: editPrompt },
        ],
      },
    ],
  };
  if (aspectRatio) {
    body.image_config = { aspect_ratio: aspectRatio };
  }

  const res = await fetch(OPENROUTER_BASE, {
    method: 'POST',
    headers: openrouterHeaders(),
    body: JSON.stringify(body),
  });

  if (!res.ok) return null;

  const data = await res.json();
  const choice = data.choices?.[0]?.message;
  if (!choice) return null;

  if (choice.images && Array.isArray(choice.images)) {
    for (const img of choice.images) {
      const url = img.image_url?.url || img.url;
      if (url) return url;
    }
  }
  return null;
}

// â”€â”€ Multi-Reference Image Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Used by agent when originalImage is available alongside currentImage.
// Each image gets a labeled role so Gemini knows what to do with each.

export interface ImageReference {
  url: string;   // base64 data URL
  role: string;  // e.g. "åŸå›¾ï¼ˆäººè„¸/äººç‰©ä¿çœŸå‚è€ƒï¼‰", "å½“å‰ç¼–è¾‘ç‰ˆæœ¬ï¼ˆç¼–è¾‘åŸºç¡€ï¼‰"
}

export async function generateImageWithReferences(
  images: ImageReference[],
  editPrompt: string,
  aspectRatio?: string,
): Promise<string | null> {
  // Build a prompt that labels each image by its role
  const imageLabels = images
    .map((img, i) => `[å›¾ç‰‡${i + 1}: ${img.role}]`)
    .join('\n');
  const fullPrompt = `${imageLabels}\n\n${editPrompt}`;

  const urls = images.map(img => img.url);
  const result = await generateWithMultipleImages(urls, fullPrompt, true);

  if (result.image) {
    console.log('âœ… [generateImageWithReferences] multi-image generation succeeded');
    return result.image;
  }
  // Fallback: if multi-image failed, use single-image on the first image (edit base = images[0])
  // NOTE: images[0] is currentImage (edit base), images[last] is originalImage (reference only)
  console.warn('âš ï¸ [generateImageWithReferences] multi-image failed, falling back to single image');
  const base = images[0].url;
  return PROVIDER === 'openrouter'
    ? generatePreviewImageOpenRouter(base, editPrompt, aspectRatio)
    : generatePreviewImageGoogle(base, editPrompt, aspectRatio);
}

// â”€â”€ Multi-Image Generation (for experiments) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function generateWithMultipleImages(
  images: string[],       // base64 data URLs
  prompt: string,
  wantImage: boolean,
): Promise<{ text?: string; image?: string }> {
  if (PROVIDER === 'openrouter') {
    return generateMultiImageOpenRouter(images, prompt, wantImage);
  } else {
    return generateMultiImageGoogle(images, prompt, wantImage);
  }
}

async function generateMultiImageGoogle(
  images: string[],
  prompt: string,
  wantImage: boolean,
): Promise<{ text?: string; image?: string }> {
  const parts: Array<{ text?: string; inlineData?: { mimeType: string; data: string } }> = [];

  for (const img of images) {
    const base64Data = img.replace(/^data:image\/\w+;base64,/, '');
    const mimeType = img.startsWith('data:image/png') ? 'image/png' : 'image/jpeg';
    parts.push({ inlineData: { mimeType, data: base64Data } });
  }
  parts.push({ text: prompt });

  const config: Record<string, unknown> = {
    responseModalities: wantImage ? ['TEXT', 'IMAGE'] : ['TEXT'],
  };

  const result = await getAI().models.generateContent({
    model: MODEL,
    contents: [{ role: 'user', parts }],
    config,
  });

  const resultParts = result.candidates?.[0]?.content?.parts;
  if (!resultParts) return {};

  let text: string | undefined;
  let image: string | undefined;

  for (const part of resultParts) {
    if (part.inlineData?.data) {
      const mime = part.inlineData.mimeType || 'image/png';
      image = `data:${mime};base64,${part.inlineData.data}`;
    } else if (part.text) {
      text = (text || '') + part.text;
    }
  }

  return { text, image };
}

async function generateMultiImageOpenRouter(
  images: string[],
  prompt: string,
  wantImage: boolean,
): Promise<{ text?: string; image?: string }> {
  const content: Array<Record<string, unknown>> = [];

  for (const img of images) {
    const dataUrl = img.startsWith('data:') ? img : `data:image/jpeg;base64,${img}`;
    content.push({ type: 'image_url', image_url: { url: dataUrl } });
  }
  content.push({ type: 'text', text: prompt });

  const body: Record<string, unknown> = {
    model: OPENROUTER_MODEL,
    stream: false,
    temperature: 1.0,
    messages: [
      { role: 'user', content },
    ],
  };

  if (wantImage) {
    body.modalities = ['image', 'text'];
  }

  const res = await fetch(OPENROUTER_BASE, {
    method: 'POST',
    headers: openrouterHeaders(),
    body: JSON.stringify(body),
  });

  if (!res.ok) {
    const errText = await res.text();
    throw new Error(`OpenRouter multi-image error ${res.status}: ${errText}`);
  }

  const data = await res.json();
  const choice = data.choices?.[0]?.message;
  if (!choice) return {};

  const text: string | undefined = choice.content || undefined;
  let image: string | undefined;

  if (choice.images && Array.isArray(choice.images)) {
    for (const img of choice.images) {
      const url = img.image_url?.url || img.url;
      if (url) { image = url; break; }
    }
  }

  return { text, image };
}

// â”€â”€ Streaming All Tips (single call for all 6) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Faster than 3 parallel calls â€” one API round trip, streams tips incrementally

// â”€â”€ Fast Tips Phase 1: emoji+label+desc+category only (no editPrompt) â”€â”€â”€â”€â”€â”€
// Very short prompt â†’ ~3s to first result (vs 8-10s with full .md templates)

const FAST_TIPS_SYSTEM = `ä½ æ˜¯å›¾ç‰‡ç¼–è¾‘å»ºè®®ä¸“å®¶ã€‚å¿«é€Ÿåˆ†æå›¾ç‰‡ç»™å‡º6æ¡ç¼–è¾‘æ–¹å‘ï¼ˆ2 enhance + 2 creative + 2 wildï¼‰ã€‚
labelä¸­æ–‡3-6å­—åŠ¨è¯å¼€å¤´ã€‚descä¸­æ–‡10-20å­—ã€‚ä¸éœ€è¦editPromptã€‚`;

const FAST_TIPS_FORMAT = `\n\nè¯·ä»¥JSONæ•°ç»„è¾“å‡ºï¼Œåªè¾“å‡ºJSONï¼š
[{"emoji":"1ä¸ªemoji","label":"ä¸­æ–‡3-6å­—","desc":"ä¸­æ–‡10-20å­—æè¿°","category":"enhance|creative|wild"}, ...]`;

export async function* streamFastTips(imageBase64: string): AsyncGenerator<Omit<Tip, 'editPrompt'> & { editPrompt?: string }> {
  if (process.env.MOCK_AI === 'true') {
    for (const cat of ['enhance', 'creative', 'wild'] as const) {
      yield* streamTipsByCategory(imageBase64, cat);
    }
    return;
  }
  const dataUrl = imageBase64.startsWith('data:') ? imageBase64 : `data:image/jpeg;base64,${imageBase64}`;
  const res = await fetch(OPENROUTER_BASE, {
    method: 'POST',
    headers: openrouterHeaders(),
    body: JSON.stringify({
      model: OPENROUTER_MODEL,
      stream: true,
      messages: [
        { role: 'system', content: FAST_TIPS_SYSTEM },
        {
          role: 'user',
          content: [
            { type: 'image_url', image_url: { url: dataUrl } },
            { type: 'text', text: `åˆ†æå›¾ç‰‡ï¼ˆåˆ¤æ–­äººè„¸å¤§å°ã€å…·ä½“ç‰©å“ã€æƒ…ç»ªåŸºè°ƒï¼‰ï¼Œç»™å‡º6æ¡å»ºè®®ï¼ˆ2 enhance + 2 creative + 2 wildï¼‰ã€‚åªè¾“å‡ºemoji+label+desc+categoryã€‚${FAST_TIPS_FORMAT}` },
          ],
        },
      ],
    }),
  });
  if (!res.ok) throw new Error(`Fast tips error ${res.status}`);

  // Reuse incremental parser â€” tips without editPrompt are fine here
  for await (const tip of parseIncrementalTipsFromStream(sseToTextIterator(res))) {
    yield tip;
  }
}

// â”€â”€ EditPrompt generation for a single tip (Phase 2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export async function generateEditPromptForTip(
  imageBase64: string,
  tip: { emoji: string; label: string; desc: string; category: string },
): Promise<string | null> {
  const dataUrl = imageBase64.startsWith('data:') ? imageBase64 : `data:image/jpeg;base64,${imageBase64}`;
  const cat = tip.category as 'enhance' | 'creative' | 'wild';
  const template = PROMPT_TEMPLATES[cat] ?? '';
  const systemPrompt = buildCategorySystemPrompt(cat);

  const res = await fetch(OPENROUTER_BASE, {
    method: 'POST',
    headers: openrouterHeaders(),
    body: JSON.stringify({
      model: OPENROUTER_MODEL,
      stream: false,
      messages: [
        { role: 'system', content: systemPrompt },
        {
          role: 'user',
          content: [
            { type: 'image_url', image_url: { url: dataUrl } },
            {
              type: 'text',
              text: `è¿™å¼ å›¾ç‰‡æœ‰ä¸€æ¡ç¼–è¾‘å»ºè®®ï¼š${tip.emoji} ${tip.label}ï¼ˆ${tip.desc}ï¼‰\n\nä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„èŒƒï¼Œä¸ºè¿™æ¡å»ºè®®ç”Ÿæˆè¯¦ç»†çš„ editPromptï¼ˆè‹±æ–‡ï¼Œ200è¯ä»¥å†…ï¼‰ã€‚åªè¾“å‡º editPrompt å­—ç¬¦ä¸²æœ¬èº«ï¼Œä¸è¦ JSONï¼Œä¸è¦è§£é‡Šã€‚\n\n${template}`,
            },
          ],
        },
      ],
    }),
  });

  if (!res.ok) return null;
  const data = await res.json();
  const text = data.choices?.[0]?.message?.content;
  return typeof text === 'string' ? text.trim() : null;
}

export async function* streamAllTips(imageBase64: string): AsyncGenerator<Tip> {
  for (const cat of ['enhance', 'creative', 'wild'] as const) {
    yield* streamTipsByCategory(imageBase64, cat);
  }
}

// â”€â”€ Streaming Tips Generation (per-category) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function* streamTipsByCategory(
  imageBase64: string,
  category: TipCategory,
  metadata?: { takenAt?: string; location?: string },
): AsyncGenerator<Tip> {
  if (process.env.MOCK_AI === 'true') {
    const mockTips: Record<string, Tip[]> = {
      enhance: [
        { emoji: 'ğŸŒ…', label: 'ç”µå½±æ„Ÿå…‰å½±', desc: 'å¢å¼ºå…‰å½±å¯¹æ¯”ï¼Œè¥é€ ç”µå½±çº§æ°›å›´ã€‚', editPrompt: 'Enhance with cinematic lighting, add warm golden hour glow, increase contrast between highlights and shadows.', category: 'enhance' },
        { emoji: 'ğŸ“·', label: 'èƒ¶ç‰‡è´¨æ„Ÿ', desc: 'æ·»åŠ æŸ”å’Œé¢—ç²’å’Œå¤å¤è‰²è°ƒã€‚', editPrompt: 'Apply analog film look with soft grain, slightly faded blacks, and warm vintage color grading.', category: 'enhance' },
      ],
      creative: [
        { emoji: 'ğŸ¦‹', label: 'è´è¶åœé©»', desc: 'ä¸€åªè“è‰²è´è¶åœåœ¨è‚©è†€ä¸Šã€‚', editPrompt: 'Add a photorealistic blue morpho butterfly perched on the shoulder, with natural shadow and lighting matching the scene.', category: 'creative' },
        { emoji: 'ğŸŒ¸', label: 'æ¨±èŠ±é£˜è½', desc: 'ç”»é¢ä¸­é£˜è½å‡ ç‰‡ç²‰è‰²èŠ±ç“£ã€‚', editPrompt: 'Add several photorealistic pink cherry blossom petals gently falling through the scene with natural depth of field blur.', category: 'creative' },
      ],
      wild: [
        { emoji: 'ğŸ”®', label: 'å¾®ç¼©ä¸–ç•Œ', desc: 'åœºæ™¯å˜æˆç²¾è‡´çš„å¾®ç¼©æ¨¡å‹ã€‚', editPrompt: 'Transform the entire scene into a tilt-shift miniature model with exaggerated depth of field and saturated colors.', category: 'wild' },
        { emoji: 'ğŸŒŠ', label: 'æ°´ä¸‹å¹»å¢ƒ', desc: 'æ•´ä¸ªç”»é¢æ²‰å…¥æ¢¦å¹»çš„æ°´ä¸‹ä¸–ç•Œã€‚', editPrompt: 'Transform the scene to appear submerged underwater with light rays filtering from above, floating bubbles, and caustic light patterns.', category: 'wild' },
      ],
      captions: [
        { emoji: 'âœï¸', label: 'åŠ åˆ›æ„æ–‡æ¡ˆ', desc: 'å åŠ ä¸ç”»é¢é«˜åº¦ç›¸å…³çš„åˆ›æ„æ–‡å­—ã€‚', editPrompt: 'Add a photorealistic text overlay with a creative caption specific to this image. Use elegant cursive script in warm cream color at the bottom-third of the image with a subtle drop shadow for readability. Preserve the exact composition and all people\'s faces exactly.', category: 'captions' },
        { emoji: 'ğŸ“', label: 'åŠ è¯—æ„æ ‡é¢˜', desc: 'ç”¨è¯—æ„è¯­è¨€ä¸ºç”»é¢å‘½åã€‚', editPrompt: 'Add a photorealistic text overlay with a poetic title for this image. Use clean minimal sans-serif font in soft white color, centered at the bottom of the image with a semi-transparent overlay behind the text. Preserve the exact composition and all people\'s faces exactly.', category: 'captions' },
      ],
    };
    const tips = mockTips[category] || mockTips.enhance;
    for (const tip of tips) {
      await new Promise(r => setTimeout(r, 200));
      yield tip;
    }
    return;
  }

  if (PROVIDER === 'openrouter') {
    yield* streamTipsByCategoryOpenRouter(imageBase64, category, metadata);
  } else {
    yield* streamTipsByCategoryGoogle(imageBase64, category, metadata);
  }
}

// --- Google Provider ---
async function* streamTipsByCategoryGoogle(
  imageBase64: string,
  category: TipCategory,
  metadata?: { takenAt?: string; location?: string },
): AsyncGenerator<Tip> {
  const base64Data = imageBase64.replace(/^data:image\/\w+;base64,/, '');
  const mimeType = imageBase64.startsWith('data:image/png') ? 'image/png' : 'image/jpeg';
  const template = getPromptTemplate(category);
  const systemPrompt = buildCategorySystemPrompt(category);
  const metaLines: string[] = [];
  if (metadata?.takenAt) metaLines.push(`æ‹æ‘„æ—¶é—´ï¼š${metadata.takenAt}`);
  if (metadata?.location) metaLines.push(`æ‹æ‘„åœ°ç‚¹ï¼š${metadata.location}`);
  const metaContext = metaLines.length > 0
    ? `[ç…§ç‰‡å…ƒæ•°æ®]\n${metaLines.join('\n')}\nï¼ˆå¯ç»“åˆåœ°ç‚¹/æ—¶é—´ç”Ÿæˆæ›´è´´åˆ‡çš„å»ºè®®ï¼‰\n\n`
    : '';

  const supportsStructuredOutput = MODEL.includes('gemini-3');
  const config: Record<string, unknown> = {
    systemInstruction: systemPrompt,
  };
  if (supportsStructuredOutput) {
    config.responseMimeType = 'application/json';
    config.responseSchema = TIPS_SCHEMA;
  }

  const promptSuffix = supportsStructuredOutput ? '' : JSON_FORMAT_SUFFIX;

  const stream = await getAI().models.generateContentStream({
    model: MODEL,
    contents: [
      {
        role: 'user',
        parts: [
          { inlineData: { mimeType, data: base64Data } },
          {
            text: `${metaContext}åœ¨ç”Ÿæˆå»ºè®®ä¹‹å‰ï¼Œå…ˆåˆ†æè¿™å¼ å›¾ç‰‡ï¼šåˆ¤æ–­äººè„¸å¤§å°ï¼ˆå¤§è„¸>10% / å°è„¸<10%ï¼‰ï¼›è¯†åˆ«ç”»é¢ä¸­çš„å…·ä½“ç‰©å“/é£Ÿç‰©/é“å…·ï¼›åˆ¤æ–­ç…§ç‰‡æƒ…ç»ªåŸºè°ƒã€‚

åŸºäºåˆ†æï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹æ‰€æœ‰è§„åˆ™ï¼Œç»™å‡º2æ¡${category}ç¼–è¾‘å»ºè®®ï¼š

${template}${promptSuffix}`,
          },
        ],
      },
    ],
    config,
  });

  yield* parseIncrementalTipsFromStream(streamToTextIterator(stream));
}

// --- OpenRouter Provider ---
async function* streamTipsByCategoryOpenRouter(
  imageBase64: string,
  category: TipCategory,
  metadata?: { takenAt?: string; location?: string },
): AsyncGenerator<Tip> {
  const dataUrl = imageBase64.startsWith('data:') ? imageBase64 : `data:image/jpeg;base64,${imageBase64}`;
  const template = getPromptTemplate(category);
  const systemPrompt = buildCategorySystemPrompt(category);
  const metaLines: string[] = [];
  if (metadata?.takenAt) metaLines.push(`æ‹æ‘„æ—¶é—´ï¼š${metadata.takenAt}`);
  if (metadata?.location) metaLines.push(`æ‹æ‘„åœ°ç‚¹ï¼š${metadata.location}`);
  const metaContext = metaLines.length > 0
    ? `[ç…§ç‰‡å…ƒæ•°æ®]\n${metaLines.join('\n')}\nï¼ˆå¯ç»“åˆåœ°ç‚¹/æ—¶é—´ç”Ÿæˆæ›´è´´åˆ‡çš„å»ºè®®ï¼‰\n\n`
    : '';

  const res = await fetch(OPENROUTER_BASE, {
    method: 'POST',
    headers: openrouterHeaders(),
    body: JSON.stringify({
      model: OPENROUTER_MODEL,
      stream: true,
      messages: [
        { role: 'system', content: systemPrompt },
        {
          role: 'user',
          content: [
            { type: 'image_url', image_url: { url: dataUrl } },
            {
              type: 'text',
              text: `${metaContext}åœ¨ç”Ÿæˆå»ºè®®ä¹‹å‰ï¼Œå…ˆåˆ†æè¿™å¼ å›¾ç‰‡ï¼šåˆ¤æ–­äººè„¸å¤§å°ï¼ˆå¤§è„¸>10% / å°è„¸<10%ï¼‰ï¼›è¯†åˆ«ç”»é¢ä¸­çš„å…·ä½“ç‰©å“/é£Ÿç‰©/é“å…·ï¼›åˆ¤æ–­ç…§ç‰‡æƒ…ç»ªåŸºè°ƒã€‚

åŸºäºåˆ†æï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹æ‰€æœ‰è§„åˆ™ï¼Œç»™å‡º2æ¡${category}ç¼–è¾‘å»ºè®®ï¼š

${template}${JSON_FORMAT_SUFFIX}`,
            },
          ],
        },
      ],
    }),
  });

  if (!res.ok) {
    const errText = await res.text();
    throw new Error(`OpenRouter tips error ${res.status}: ${errText}`);
  }

  yield* parseIncrementalTipsFromStream(sseToTextIterator(res));
}

// â”€â”€ Shared Incremental JSON Parser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function* streamToTextIterator(
  stream: AsyncIterable<{ candidates?: Array<{ content?: { parts?: Array<{ text?: string }> } }> }>,
): AsyncGenerator<string> {
  for await (const chunk of stream) {
    const text = chunk.candidates?.[0]?.content?.parts?.[0]?.text;
    if (text) yield text;
  }
}

async function* sseToTextIterator(res: Response): AsyncGenerator<string> {
  const reader = res.body!.getReader();
  const decoder = new TextDecoder();
  let buffer = '';

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    buffer += decoder.decode(value, { stream: true });

    const lines = buffer.split('\n');
    buffer = lines.pop() || '';

    for (const line of lines) {
      if (!line.startsWith('data: ')) continue;
      const payload = line.slice(6).trim();
      if (payload === '[DONE]') return;
      try {
        const chunk = JSON.parse(payload);
        const text = chunk.choices?.[0]?.delta?.content;
        if (text) yield text;
      } catch { /* skip */ }
    }
  }
}

async function* parseIncrementalTipsFromStream(
  textStream: AsyncIterable<string>,
): AsyncGenerator<Tip> {
  let fullText = '';
  let tipsEmitted = 0;

  for await (const text of textStream) {
    fullText += text;

    let objectsFound = 0;
    for (let i = 0; i < fullText.length; i++) {
      if (fullText[i] === '{') {
        let depth = 1;
        let j = i + 1;
        while (j < fullText.length && depth > 0) {
          if (fullText[j] === '{') depth++;
          else if (fullText[j] === '}') depth--;
          j++;
        }
        if (depth === 0) {
          objectsFound++;
          if (objectsFound > tipsEmitted) {
            const objStr = fullText.slice(i, j);
            try {
              const tip = JSON.parse(objStr) as Tip;
              if (tip.label && tip.editPrompt && tip.category) {
                yield tip;
              }
            } catch { /* incomplete or malformed, skip */ }
            tipsEmitted = objectsFound;
          }
          i = j - 1;
        }
      }
    }
  }
}
